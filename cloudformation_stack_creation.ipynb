{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloudformation Stack Creation\n",
    "\n",
    "This step is responsible to create all required AWS services to host the cluster. We will use one special AWS service called **CloudFormation** to create required services.\n",
    "Following AWS services are used to host the cluster:\n",
    "* A VPC\n",
    "* Two subnets\n",
    "* A Security Group allowing traffic to-fro cluster\n",
    "* An Inteenet Gateway\n",
    "* One VPC-IGW Attachment\n",
    "* A Route Table\n",
    "* One Subnet Association for each Subnet\n",
    "* One Route to the IGW in the RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries ::\n",
    "* __boto3__: Required to connect as operate AWS task\n",
    "* __botocore__: Required to handle the exceptions related to boto3 tasks\n",
    "* __paramiko__: Reuired to run commands inside EC2 instances\n",
    "* __json__: To convert python native dictionaries to string, to write in files\n",
    "* __pickle__: To store configuration dictionary which will be used in next notebooks\n",
    "* __datetime__, __pprint__, __sys__, __time__: General purpose use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, botocore, paramiko\n",
    "from datetime import datetime\n",
    "import pprint, sys, time, json, pickle\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading user defined configurations & Declaring other variables::\n",
    "* User is allowed to provide specific configurations using provided format of configuration file. If user does not provide any confguration or provides wrong configuration format, then default values will be used. Please check **README.MD** file for default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"cluster_config.json\", \"r\") as config_file:\n",
    "        user_config = json.load(config_file)\n",
    "\n",
    "    run_id = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "    user_config['RunId'] = run_id\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boto3 session, clients and resources::\n",
    "These resources will be used to connect and run different tasks on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session = boto3.session.Session(region_name=user_config.get('Region', \"us-east-1\"))\n",
    "    cf_client = session.client('cloudformation')\n",
    "    cf_resource = session.resource('cloudformation')\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating boto3 session, client and resources: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for already running Stck under current user::\n",
    "For each user only one cluster is allowed. Hence only one ACTIVE stack is allowed for each user. In this section we will check if there are existing Stack in ACTIVE status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cf_stack_details = cf_client.list_stacks(\n",
    "        StackStatusFilter=[\n",
    "            'CREATE_IN_PROGRESS', 'CREATE_COMPLETE', 'ROLLBACK_IN_PROGRESS', 'DELETE_IN_PROGRESS', 'UPDATE_IN_PROGRESS', 'UPDATE_COMPLETE_CLEANUP_IN_PROGRESS', 'UPDATE_COMPLETE', 'UPDATE_ROLLBACK_IN_PROGRESS', 'UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS', 'UPDATE_ROLLBACK_COMPLETE', 'REVIEW_IN_PROGRESS', 'IMPORT_IN_PROGRESS', 'IMPORT_COMPLETE', 'IMPORT_ROLLBACK_IN_PROGRESS', 'IMPORT_ROLLBACK_COMPLETE'\n",
    "        ]\n",
    "    )\n",
    "    stack_list = cf_stack_details['StackSummaries']\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stack_exists_flag = False\n",
    "    for stack in stack_list:\n",
    "        stack_desc = cf_client.describe_stacks(StackName=stack['StackId'])\n",
    "        for fetched_stack in stack_desc['Stacks']:\n",
    "            tag_count = 2\n",
    "            for tag in fetched_stack['Tags']:\n",
    "                if ((tag['Key'] == \"Project\") and (tag['Value'] == user_config.get('ProjectTag', \"SparkCluster\"))) or ((tag['Key'] == \"User\") and (tag['Value'] == user_config.get('UserName', \"root\"))):\n",
    "                    tag_count -= 1\n",
    "            if tag_count <= 0:\n",
    "                print(\"User('\" + user_config.get('UserName', \"root\") + \"') already has one existing ACTIVE Spark Cluster stack. Only one stack is allowed at a time.\")\n",
    "                stack_exists_flag = True\n",
    "                break\n",
    "        if stack_exists_flag:\n",
    "            break\n",
    "    if stack_exists_flag:\n",
    "    #     exit()\n",
    "        stack_exists_flag = False\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Creation\n",
    "If any Spark Cluster is not ACTIVE for current User, one spark cluster stack will be created.\n",
    "\n",
    "**Note:** *This stack will not launch any node instance, node instances are launched separately. Here supporting services like VPC, Subnet etc will be created.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        available_az_list = user_config.get('AZList', ['us-east-1a', 'us-east-1b'])\n",
    "        if available_az_list:\n",
    "            az_1 = available_az_list[0]\n",
    "            if len(available_az_list) >= 2:\n",
    "                az_2 = available_az_list[1]\n",
    "            else:\n",
    "                az_2 = available_az_list[0]\n",
    "        else:\n",
    "            az_1, az_2 = ('us-east-1a', 'us-east-1b')\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Base properties to the template\n",
    "Following parameters will be required while executing the template:\n",
    "* AWSTemplateFormatVersion\n",
    "* Description\n",
    "* Parameters(empty)\n",
    "* Resources(empty)\n",
    "* Outputs(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template = {\n",
    "            \"AWSTemplateFormatVersion\": \"2010-09-09\",\n",
    "            \"Description\" : \"This template is used to create Stack for SparkClusterUsingAWSEC2 utility.\",\n",
    "            \"Parameters\" : {},\n",
    "            \"Resources\" : {},\n",
    "            \"Outputs\" : ()\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Required parameter definition to the template\n",
    "Following parameters will be required while executing the template:\n",
    "* VPC CIDR Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Parameters']['SparkClusterCIDR'] = {\n",
    "            \"Description\": \"Provide the IP4 CIDR block that will be used by the VPC.\",\n",
    "            \"Type\": \"String\",\n",
    "            \"AllowedPattern\" : \"[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}/[0-9]{1,3}\"\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding VPC to the template\n",
    "* SparkClusterVPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Resources']['SparkClusterVPC'] = {\n",
    "            \"Type\" : \"AWS::EC2::VPC\",\n",
    "            \"Properties\" : {\n",
    "                \"CidrBlock\" : {\n",
    "                    \"Ref\" : \"SparkClusterCIDR\"\n",
    "                },\n",
    "                \"EnableDnsHostnames\" : True,\n",
    "                \"EnableDnsSupport\" : True,\n",
    "                \"Tags\" : [\n",
    "                    {\n",
    "                        \"Key\" : \"Project\",\n",
    "                        \"Value\" : user_config.get('ProjectTag', \"SparkCluster\")\n",
    "                    },\n",
    "                    {\n",
    "                        \"Key\" : \"User\",\n",
    "                        \"Value\" : user_config.get('UserName', \"root\")\n",
    "                    },\n",
    "                    {\n",
    "                        \"Key\" : \"Name\",\n",
    "                        \"Value\" : \"SparkClusterVPC_\" + run_id\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding two Subnets to the template\n",
    "* SparkClusterSubnet1\n",
    "* SparkClusterSubnet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Resources']['SparkClusterSubnet1'] = {\n",
    "            \"Type\" : \"AWS::EC2::Subnet\",\n",
    "            \"Properties\" : {\n",
    "                \"AvailabilityZone\" : az_1,\n",
    "                \"CidrBlock\" : {\n",
    "                    \"Fn::Select\" : [\n",
    "                        0,\n",
    "                        {\n",
    "                            \"Fn::Cidr\" : [\n",
    "                                {\n",
    "                                    \"Fn::GetAtt\" : [ \"SparkClusterVPC\", \"CidrBlock\" ]\n",
    "                                },\n",
    "                                2,\n",
    "                                9\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"MapPublicIpOnLaunch\" : True,\n",
    "                \"Tags\" : [\n",
    "                    {\n",
    "                       \"Key\" : \"Project\",\n",
    "                       \"Value\" : user_config.get('ProjectTag', \"SparkCluster\")\n",
    "                    },\n",
    "                    {\n",
    "                        \"Key\" : \"User\",\n",
    "                        \"Value\" : user_config.get('UserName', \"root\")\n",
    "                    },\n",
    "                    {\n",
    "                       \"Key\" : \"Name\",\n",
    "                       \"Value\" : \"SparkClusterSubnet1_\" + run_id\n",
    "                    }\n",
    "                ],\n",
    "                \"VpcId\" : {\n",
    "                    \"Ref\" : \"SparkClusterVPC\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        stack_template['Resources']['SparkClusterSubnet2'] = {\n",
    "            \"Type\" : \"AWS::EC2::Subnet\",\n",
    "            \"Properties\" : {\n",
    "                \"AvailabilityZone\" : az_2,\n",
    "                \"CidrBlock\" : {\n",
    "                    \"Fn::Select\" : [\n",
    "                        1,\n",
    "                        {\n",
    "                            \"Fn::Cidr\" : [\n",
    "                                {\n",
    "                                    \"Fn::GetAtt\" : [ \"SparkClusterVPC\", \"CidrBlock\" ]\n",
    "                                },\n",
    "                                2,\n",
    "                                9\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"MapPublicIpOnLaunch\" : True,\n",
    "                \"Tags\" : [\n",
    "                    {\n",
    "                       \"Key\" : \"Project\",\n",
    "                       \"Value\" : user_config.get('ProjectTag', \"SparkCluster\")\n",
    "                    },\n",
    "                    {\n",
    "                        \"Key\" : \"User\",\n",
    "                        \"Value\" : user_config.get('UserName', \"root\")\n",
    "                    },\n",
    "                    {\n",
    "                       \"Key\" : \"Name\",\n",
    "                       \"Value\" : \"SparkClusterSubnet2_\" + run_id\n",
    "                    }\n",
    "                ],\n",
    "                \"VpcId\" : {\n",
    "                    \"Ref\" : \"SparkClusterVPC\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Security Group to the template\n",
    "* SparkClusterSecurityGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Resources']['SparkClusterSecurityGroup'] = {\n",
    "            \"Type\" : \"AWS::EC2::SecurityGroup\",\n",
    "            \"Properties\" : {\n",
    "                \"GroupDescription\" : \"This securty group will filter inbound and outbound traffic to the cluster.\",\n",
    "                \"GroupName\" : \"SparkClusterSecurityGroup_\" + run_id,\n",
    "                \"Tags\" : [\n",
    "                    {\n",
    "                       \"Key\" : \"Project\",\n",
    "                       \"Value\" : user_config.get('ProjectTag', \"SparkCluster\")\n",
    "                    },\n",
    "                    {\n",
    "                        \"Key\" : \"User\",\n",
    "                        \"Value\" : user_config.get('UserName', \"root\")\n",
    "                    },\n",
    "                    {\n",
    "                       \"Key\" : \"Name\",\n",
    "                       \"Value\" : \"SparkClusterSecurityGroup_\" + run_id\n",
    "                    }\n",
    "                ],\n",
    "                \"VpcId\" : {\n",
    "                    \"Ref\" : \"SparkClusterVPC\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding default inbound & outbound rules to the template\n",
    "* SparkClusterSGIngress1\n",
    "* SparkClusterSGEgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Resources']['SparkClusterSGIngress1'] = {\n",
    "            \"Type\": \"AWS::EC2::SecurityGroupIngress\",\n",
    "            \"Properties\": {\n",
    "                \"GroupId\": { \n",
    "                    \"Ref\": \"SparkClusterSecurityGroup\"\n",
    "                },\n",
    "                \"IpProtocol\": \"-1\",\n",
    "                \"FromPort\": \"-1\",\n",
    "                \"ToPort\": \"-1\",\n",
    "                \"CidrIp\": {\n",
    "                    \"Fn::GetAtt\" : [ \"SparkClusterVPC\", \"CidrBlock\" ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        stack_template['Resources']['SparkClusterSGEgress'] = {\n",
    "            \"Type\": \"AWS::EC2::SecurityGroupEgress\",\n",
    "            \"Properties\": {\n",
    "                \"GroupId\": { \n",
    "                    \"Ref\": \"SparkClusterSecurityGroup\"\n",
    "                },\n",
    "                \"IpProtocol\": \"-1\",\n",
    "                \"FromPort\": \"-1\",\n",
    "                \"ToPort\": \"-1\",\n",
    "                \"CidrIp\": \"0.0.0.0/0\"\n",
    "            }\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create InternetGateway and Attach it to VPC\n",
    "* Create Internet Gateway to allow traffic to the Spark Nodes\n",
    "* Attach it to the Spark Cluster VPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Resources']['SparkClusterIGW'] = {\n",
    "            \"Type\": \"AWS::EC2::InternetGateway\",\n",
    "            \"Properties\" : {\n",
    "                \"Tags\" : [\n",
    "                    {\n",
    "                       \"Key\" : \"Project\",\n",
    "                       \"Value\" : user_config.get('ProjectTag', \"SparkCluster\")\n",
    "                    },\n",
    "                    {\n",
    "                        \"Key\" : \"User\",\n",
    "                        \"Value\" : user_config.get('UserName', \"root\")\n",
    "                    },\n",
    "                    {\n",
    "                       \"Key\" : \"Name\",\n",
    "                       \"Value\" : \"SparkClusterSecurityGroup_\" + run_id\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stack_template['Resources']['SparkClusterIGWAttachment'] = {\n",
    "            \"Type\" : \"AWS::EC2::VPCGatewayAttachment\",\n",
    "            \"Properties\" : {\n",
    "                \"VpcId\" : {\n",
    "                    \"Ref\" : \"SparkClusterVPC\" \n",
    "                },\n",
    "                \"InternetGatewayId\" : {\n",
    "                    \"Ref\" : \"SparkClusterIGW\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Router table creation and configuration\n",
    "* Create one route table\n",
    "* Associate created subnets to the RT\n",
    "* Add one route to the created IGW in the RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Resources']['SparkClusterRT'] = {\n",
    "            \"Type\" : \"AWS::EC2::RouteTable\",\n",
    "            \"Properties\" : {\n",
    "                \"VpcId\" : {\n",
    "                    \"Ref\" : \"SparkClusterVPC\"\n",
    "                },\n",
    "                \"Tags\" : [\n",
    "                    {\n",
    "                       \"Key\" : \"Project\",\n",
    "                       \"Value\" : user_config.get('ProjectTag', \"SparkCluster\")\n",
    "                    },\n",
    "                    {\n",
    "                        \"Key\" : \"User\",\n",
    "                        \"Value\" : user_config.get('UserName', \"root\")\n",
    "                    },\n",
    "                    {\n",
    "                       \"Key\" : \"Name\",\n",
    "                       \"Value\" : \"SparkClusterSecurityGroup_\" + run_id\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stack_template['Resources']['SparkClusterSubnetRTAssociation1'] = {\n",
    "        \"Type\" : \"AWS::EC2::SubnetRouteTableAssociation\",\n",
    "            \"Properties\" : {\n",
    "                \"SubnetId\" : {\n",
    "                    \"Ref\" : \"SparkClusterSubnet1\"\n",
    "                },\n",
    "                \"RouteTableId\" : {\n",
    "                    \"Ref\" : \"SparkClusterRT\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stack_template['Resources']['SparkClusterSubnetRTAssociation2'] = {\n",
    "        \"Type\" : \"AWS::EC2::SubnetRouteTableAssociation\",\n",
    "            \"Properties\" : {\n",
    "                \"SubnetId\" : {\n",
    "                    \"Ref\" : \"SparkClusterSubnet2\"\n",
    "                },\n",
    "                \"RouteTableId\" : {\n",
    "                    \"Ref\" : \"SparkClusterRT\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stack_template['Resources']['SparkClusterRoute'] = {\n",
    "            \"Type\" : \"AWS::EC2::Route\",\n",
    "            \"DependsOn\" : \"SparkClusterIGW\",\n",
    "            \"Properties\" : {\n",
    "                \"RouteTableId\" : {\n",
    "                    \"Ref\" : \"SparkClusterRT\"\n",
    "                },\n",
    "                \"DestinationCidrBlock\" : \"0.0.0.0/0\",\n",
    "                \"GatewayId\" : {\n",
    "                    \"Ref\" : \"SparkClusterIGW\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Outputs to the template\n",
    "* VPCId\n",
    "* SubnetId1\n",
    "* SubnetId2\n",
    "* SecurityGroupId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        stack_template['Outputs'] = {\n",
    "            \"VPCId\" : {\n",
    "                \"Description\": \"The VPC ID\",  \n",
    "                \"Value\" : { \"Ref\" : \"SparkClusterVPC\" }\n",
    "            },\n",
    "            \"SubnetId1\" : {\n",
    "                \"Description\": \"The Subnet ID\",  \n",
    "                \"Value\" : { \"Ref\" : \"SparkClusterSubnet1\" }\n",
    "            },\n",
    "            \"SubnetId2\" : {\n",
    "                \"Description\": \"The Subnet ID\",  \n",
    "                \"Value\" : { \"Ref\" : \"SparkClusterSubnet2\" }\n",
    "            },\n",
    "            \"SecurityGroupId\" : {\n",
    "                \"Description\": \"The Security Group ID\",  \n",
    "                \"Value\" : { \"Ref\" : \"SparkClusterSecurityGroup\" }\n",
    "            }\n",
    "        }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Listing provided IPs\n",
    "* Add one separate inbound rule in the securit group for each IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        white_listed_ips = user_config.get('IPWhitelist', [])\n",
    "        if white_listed_ips:\n",
    "            for i in range(len(white_listed_ips)):\n",
    "                stack_template['Resources']['SparkClusterSGIngress' + str(i+2)] = {\n",
    "                    \"Type\": \"AWS::EC2::SecurityGroupIngress\",\n",
    "                    \"Properties\": {\n",
    "                        \"GroupId\": { \n",
    "                            \"Ref\": \"SparkClusterSecurityGroup\"\n",
    "                        },\n",
    "                        \"IpProtocol\": \"-1\",\n",
    "                        \"FromPort\": \"-1\",\n",
    "                        \"ToPort\": \"-1\",\n",
    "                        \"CidrIp\": white_listed_ips[i] if \"/\" in white_listed_ips[i] else white_listed_ips[i] + \"/32\"\n",
    "                    }\n",
    "                }\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Stack Template file\n",
    "This file will be used to create the stack using boto3 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AWSTemplateFormatVersion': '2010-09-09',\n",
      " 'Description': 'This template is used to create Stack for '\n",
      "                'SparkClusterUsingAWSEC2 utility.',\n",
      " 'Outputs': {'SecurityGroupId': {'Description': 'The Security Group ID',\n",
      "                                 'Value': {'Ref': 'SparkClusterSecurityGroup'}},\n",
      "             'SubnetId1': {'Description': 'The Subnet ID',\n",
      "                           'Value': {'Ref': 'SparkClusterSubnet1'}},\n",
      "             'SubnetId2': {'Description': 'The Subnet ID',\n",
      "                           'Value': {'Ref': 'SparkClusterSubnet2'}},\n",
      "             'VPCId': {'Description': 'The VPC ID',\n",
      "                       'Value': {'Ref': 'SparkClusterVPC'}}},\n",
      " 'Parameters': {'SparkClusterCIDR': {'AllowedPattern': '[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}/[0-9]{1,3}',\n",
      "                                     'Description': 'Provide the IP4 CIDR '\n",
      "                                                    'block that will be used '\n",
      "                                                    'by the VPC.',\n",
      "                                     'Type': 'String'}},\n",
      " 'Resources': {'SparkClusterIGW': {'Properties': {'Tags': [{'Key': 'Project',\n",
      "                                                            'Value': 'SparkCluster'},\n",
      "                                                           {'Key': 'User',\n",
      "                                                            'Value': 'ccbp-dev-user-saumalya'},\n",
      "                                                           {'Key': 'Name',\n",
      "                                                            'Value': 'SparkClusterSecurityGroup_20200331205712'}]},\n",
      "                                   'Type': 'AWS::EC2::InternetGateway'},\n",
      "               'SparkClusterIGWAttachment': {'Properties': {'InternetGatewayId': {'Ref': 'SparkClusterIGW'},\n",
      "                                                            'VpcId': {'Ref': 'SparkClusterVPC'}},\n",
      "                                             'Type': 'AWS::EC2::VPCGatewayAttachment'},\n",
      "               'SparkClusterRT': {'Properties': {'Tags': [{'Key': 'Project',\n",
      "                                                           'Value': 'SparkCluster'},\n",
      "                                                          {'Key': 'User',\n",
      "                                                           'Value': 'ccbp-dev-user-saumalya'},\n",
      "                                                          {'Key': 'Name',\n",
      "                                                           'Value': 'SparkClusterSecurityGroup_20200331205712'}],\n",
      "                                                 'VpcId': {'Ref': 'SparkClusterVPC'}},\n",
      "                                  'Type': 'AWS::EC2::RouteTable'},\n",
      "               'SparkClusterRoute': {'DependsOn': 'SparkClusterIGW',\n",
      "                                     'Properties': {'DestinationCidrBlock': '0.0.0.0/0',\n",
      "                                                    'GatewayId': {'Ref': 'SparkClusterIGW'},\n",
      "                                                    'RouteTableId': {'Ref': 'SparkClusterRT'}},\n",
      "                                     'Type': 'AWS::EC2::Route'},\n",
      "               'SparkClusterSGEgress': {'Properties': {'CidrIp': '0.0.0.0/0',\n",
      "                                                       'FromPort': '-1',\n",
      "                                                       'GroupId': {'Ref': 'SparkClusterSecurityGroup'},\n",
      "                                                       'IpProtocol': '-1',\n",
      "                                                       'ToPort': '-1'},\n",
      "                                        'Type': 'AWS::EC2::SecurityGroupEgress'},\n",
      "               'SparkClusterSGIngress1': {'Properties': {'CidrIp': {'Fn::GetAtt': ['SparkClusterVPC',\n",
      "                                                                                   'CidrBlock']},\n",
      "                                                         'FromPort': '-1',\n",
      "                                                         'GroupId': {'Ref': 'SparkClusterSecurityGroup'},\n",
      "                                                         'IpProtocol': '-1',\n",
      "                                                         'ToPort': '-1'},\n",
      "                                          'Type': 'AWS::EC2::SecurityGroupIngress'},\n",
      "               'SparkClusterSGIngress2': {'Properties': {'CidrIp': '103.77.137.192/32',\n",
      "                                                         'FromPort': '-1',\n",
      "                                                         'GroupId': {'Ref': 'SparkClusterSecurityGroup'},\n",
      "                                                         'IpProtocol': '-1',\n",
      "                                                         'ToPort': '-1'},\n",
      "                                          'Type': 'AWS::EC2::SecurityGroupIngress'},\n",
      "               'SparkClusterSGIngress3': {'Properties': {'CidrIp': '192.168.247.1/32',\n",
      "                                                         'FromPort': '-1',\n",
      "                                                         'GroupId': {'Ref': 'SparkClusterSecurityGroup'},\n",
      "                                                         'IpProtocol': '-1',\n",
      "                                                         'ToPort': '-1'},\n",
      "                                          'Type': 'AWS::EC2::SecurityGroupIngress'},\n",
      "               'SparkClusterSGIngress4': {'Properties': {'CidrIp': '52.90.143.85/32',\n",
      "                                                         'FromPort': '-1',\n",
      "                                                         'GroupId': {'Ref': 'SparkClusterSecurityGroup'},\n",
      "                                                         'IpProtocol': '-1',\n",
      "                                                         'ToPort': '-1'},\n",
      "                                          'Type': 'AWS::EC2::SecurityGroupIngress'},\n",
      "               'SparkClusterSecurityGroup': {'Properties': {'GroupDescription': 'This '\n",
      "                                                                                'securty '\n",
      "                                                                                'group '\n",
      "                                                                                'will '\n",
      "                                                                                'filter '\n",
      "                                                                                'inbound '\n",
      "                                                                                'and '\n",
      "                                                                                'outbound '\n",
      "                                                                                'traffic '\n",
      "                                                                                'to '\n",
      "                                                                                'the '\n",
      "                                                                                'cluster.',\n",
      "                                                            'GroupName': 'SparkClusterSecurityGroup_20200331205712',\n",
      "                                                            'Tags': [{'Key': 'Project',\n",
      "                                                                      'Value': 'SparkCluster'},\n",
      "                                                                     {'Key': 'User',\n",
      "                                                                      'Value': 'ccbp-dev-user-saumalya'},\n",
      "                                                                     {'Key': 'Name',\n",
      "                                                                      'Value': 'SparkClusterSecurityGroup_20200331205712'}],\n",
      "                                                            'VpcId': {'Ref': 'SparkClusterVPC'}},\n",
      "                                             'Type': 'AWS::EC2::SecurityGroup'},\n",
      "               'SparkClusterSubnet1': {'Properties': {'AvailabilityZone': 'us-east-1a',\n",
      "                                                      'CidrBlock': {'Fn::Select': [0,\n",
      "                                                                                   {'Fn::Cidr': [{'Fn::GetAtt': ['SparkClusterVPC',\n",
      "                                                                                                                 'CidrBlock']},\n",
      "                                                                                                 2,\n",
      "                                                                                                 9]}]},\n",
      "                                                      'MapPublicIpOnLaunch': True,\n",
      "                                                      'Tags': [{'Key': 'Project',\n",
      "                                                                'Value': 'SparkCluster'},\n",
      "                                                               {'Key': 'User',\n",
      "                                                                'Value': 'ccbp-dev-user-saumalya'},\n",
      "                                                               {'Key': 'Name',\n",
      "                                                                'Value': 'SparkClusterSubnet1_20200331205712'}],\n",
      "                                                      'VpcId': {'Ref': 'SparkClusterVPC'}},\n",
      "                                       'Type': 'AWS::EC2::Subnet'},\n",
      "               'SparkClusterSubnet2': {'Properties': {'AvailabilityZone': 'us-east-1b',\n",
      "                                                      'CidrBlock': {'Fn::Select': [1,\n",
      "                                                                                   {'Fn::Cidr': [{'Fn::GetAtt': ['SparkClusterVPC',\n",
      "                                                                                                                 'CidrBlock']},\n",
      "                                                                                                 2,\n",
      "                                                                                                 9]}]},\n",
      "                                                      'MapPublicIpOnLaunch': True,\n",
      "                                                      'Tags': [{'Key': 'Project',\n",
      "                                                                'Value': 'SparkCluster'},\n",
      "                                                               {'Key': 'User',\n",
      "                                                                'Value': 'ccbp-dev-user-saumalya'},\n",
      "                                                               {'Key': 'Name',\n",
      "                                                                'Value': 'SparkClusterSubnet2_20200331205712'}],\n",
      "                                                      'VpcId': {'Ref': 'SparkClusterVPC'}},\n",
      "                                       'Type': 'AWS::EC2::Subnet'},\n",
      "               'SparkClusterSubnetRTAssociation1': {'Properties': {'RouteTableId': {'Ref': 'SparkClusterRT'},\n",
      "                                                                   'SubnetId': {'Ref': 'SparkClusterSubnet1'}},\n",
      "                                                    'Type': 'AWS::EC2::SubnetRouteTableAssociation'},\n",
      "               'SparkClusterSubnetRTAssociation2': {'Properties': {'RouteTableId': {'Ref': 'SparkClusterRT'},\n",
      "                                                                   'SubnetId': {'Ref': 'SparkClusterSubnet2'}},\n",
      "                                                    'Type': 'AWS::EC2::SubnetRouteTableAssociation'},\n",
      "               'SparkClusterVPC': {'Properties': {'CidrBlock': {'Ref': 'SparkClusterCIDR'},\n",
      "                                                  'EnableDnsHostnames': True,\n",
      "                                                  'EnableDnsSupport': True,\n",
      "                                                  'Tags': [{'Key': 'Project',\n",
      "                                                            'Value': 'SparkCluster'},\n",
      "                                                           {'Key': 'User',\n",
      "                                                            'Value': 'ccbp-dev-user-saumalya'},\n",
      "                                                           {'Key': 'Name',\n",
      "                                                            'Value': 'SparkClusterVPC_20200331205712'}]},\n",
      "                                   'Type': 'AWS::EC2::VPC'}}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        pprint.pprint(stack_template)\n",
    "        with open(user_config['WorkspaceDirectory'] + \"/SparkClusterOnAWSEC2_Stack_\" + user_config['UserName'] + \"_\" + str(run_id) + \".json\", 'w') as stack_file:\n",
    "            json.dump(stack_template, stack_file)\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Stack using generated Template::\n",
    "create_stack API of boto3 library is used to launch the Stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StackId': 'arn:aws:cloudformation:us-east-1:928765701029:stack/SparkClusterStack-ccbp-dev-user-saumalya-20200331205712/193a33b0-7364-11ea-a2ca-1272d872aba7', 'ResponseMetadata': {'RequestId': '0298b947-70d5-4824-8eb1-761495fcd5ba', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '0298b947-70d5-4824-8eb1-761495fcd5ba', 'content-type': 'text/xml', 'content-length': '425', 'date': 'Tue, 31 Mar 2020 15:27:14 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if not stack_exists_flag:\n",
    "        response = cf_client.create_stack(\n",
    "            StackName=\"SparkClusterStack-\" + user_config['UserName'] + \"-\" + str(run_id),\n",
    "            TemplateBody=json.dumps(stack_template),\n",
    "            Parameters=[\n",
    "                {\n",
    "                    'ParameterKey': \"SparkClusterCIDR\",\n",
    "                    'ParameterValue': user_config['CidrBlock'].split(\"/\")[0] + \"/22\"\n",
    "                },\n",
    "            ],\n",
    "            OnFailure=\"ROLLBACK\",\n",
    "            Tags=[\n",
    "                {\n",
    "                    \"Key\" : \"Project\",\n",
    "                    \"Value\" : user_config.get('ProjectTag', \"SparkCluster\")\n",
    "                },\n",
    "                {\n",
    "                    \"Key\" : \"User\",\n",
    "                    \"Value\" : user_config.get('UserName', \"root\")\n",
    "                },\n",
    "                {\n",
    "                    \"Key\" : \"Name\",\n",
    "                    \"Value\" : \"SparkClusterVPC_\" + run_id\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        user_config['StackId'] = response['StackId']\n",
    "        print(response)\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check creation status:\n",
    "describe_stack API of boto3 library will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack creation process is still not Completed or Failed, going to sleep for 10 seconds...\n",
      "Stack creation process is still not Completed or Failed, going to sleep for 10 seconds...\n",
      "Stack creation process is still not Completed or Failed, going to sleep for 10 seconds...\n",
      "Stack creation process is still not Completed or Failed, going to sleep for 10 seconds...\n",
      "Stack creation process is still not Completed or Failed, going to sleep for 10 seconds...\n",
      "Stack creation process is still not Completed or Failed, going to sleep for 10 seconds...\n",
      "Stack('SparkClusterStack-ccbp-dev-user-saumalya-20200331205712') is created. It is ready to be used.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    stack_created_flag = False\n",
    "    if not stack_exists_flag:\n",
    "        probing_limit = 30\n",
    "        for _ in range(probing_limit):\n",
    "            stack_desc = cf_client.describe_stacks(StackName=user_config['StackId'])['Stacks'][0]\n",
    "            if stack_desc['StackStatus'] == \"CREATE_COMPLETE\":\n",
    "                print(\"Stack('\" + stack_desc['StackName'] + \"') is created. It is ready to be used.\")\n",
    "                stack_created_flag = True\n",
    "                stack_output_list = stack_desc['Outputs']\n",
    "                break\n",
    "            elif stack_desc['StackStatus'] == \"ROLLBACK_COMPLETE\":\n",
    "                print(\"Stack('\" + stack_desc['StackName'] + \"') creation has FAILED. Initiating DELETE STACK process.\")\n",
    "                cf_client.delete_stack(StackName=stack_desc['StackName'])\n",
    "                print(\"Deletion process initiated. It will take 3-4 minutes based on the network.\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Stack creation process is still not Completed or Failed, going to sleep for 10 seconds...\")\n",
    "                time.sleep(10)\n",
    "        else:\n",
    "            print(\"Maximum waitting period(5 mins) is over. Please check using AWS console.\")\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AZList': ['us-east-1a', 'us-east-1b', 'us-east-1c'],\n",
      " 'CidrBlock': '172.172.0.0/16',\n",
      " 'IPWhitelist': ['103.77.137.192', '192.168.247.1', '52.90.143.85'],\n",
      " 'InstanceType': 't2.micro',\n",
      " 'KeyPairName': 'SparkCluster',\n",
      " 'KeyPairPath': '/Volumes/WorkSpace/AWS/Access_Keys',\n",
      " 'ProjectTag': 'SparkCluster',\n",
      " 'Region': 'us-east-1',\n",
      " 'RunId': '20200331205712',\n",
      " 'SecurityGroupId': 'sg-08da31c8f5d7911e0',\n",
      " 'SlaveCount': 3,\n",
      " 'StackId': 'arn:aws:cloudformation:us-east-1:928765701029:stack/SparkClusterStack-ccbp-dev-user-saumalya-20200331205712/193a33b0-7364-11ea-a2ca-1272d872aba7',\n",
      " 'SubnetList': ['subnet-0bc031e1a7754a079', 'subnet-02a980cb830e1e85b'],\n",
      " 'UserName': 'ccbp-dev-user-saumalya',\n",
      " 'VPCId': 'vpc-00f4768a57605928b',\n",
      " 'WorkspaceDirectory': '/Volumes/WorkSpace/POC/SparkClusterEC2/WrkSpc'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if stack_created_flag:\n",
    "        stack_output_dict = {output['OutputKey']: output['OutputValue'] for output in stack_output_list}\n",
    "        user_config['VPCId'] = stack_output_dict['VPCId']\n",
    "        user_config['SubnetList'] = [stack_output_dict['SubnetId1'], stack_output_dict['SubnetId2']]\n",
    "        user_config['SecurityGroupId'] = stack_output_dict['SecurityGroupId']\n",
    "        pprint.pprint(user_config)\n",
    "\n",
    "        with open(user_config['WorkspaceDirectory'] + \"/SparkClusterOnAWSEC2_\" + user_config['UserName'] + \"_CurrentStatus.pkl\", 'wb') as pickle_handle:\n",
    "            pickle.dump(user_config, pickle_handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error while creating Cloudformation Stack: \" + str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
